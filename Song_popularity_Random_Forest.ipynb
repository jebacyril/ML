{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplement 6: Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from scipy.stats import mode\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Programming Task: Song popularity prediction using Random Forest\n",
    "The goal of this task is to train a random forest model that predicts the song popularity using the datasets already provided in task 4.3\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   danceability  key  loudness  acousticness  instrumentalness  liveness  \\\n",
      "0         0.391    8    -9.532         0.478          0.000006    0.1160   \n",
      "1         0.628    1   -13.834         0.156          0.010400    0.0836   \n",
      "2         0.613    3   -22.789         0.864          0.000000    0.2690   \n",
      "3         0.504    2    -5.931         0.414          0.000000    0.0845   \n",
      "4         0.698    9    -3.840         0.101          0.000000    0.1070   \n",
      "\n",
      "   valence    tempo  popular  \n",
      "0    0.138  105.593      0.0  \n",
      "1    0.761  102.974      0.0  \n",
      "2    0.371   75.104      0.0  \n",
      "3    0.163  135.927      1.0  \n",
      "4    0.931  124.042      1.0  \n",
      "   danceability  key  loudness  acousticness  instrumentalness  liveness  \\\n",
      "0         0.652    9    -7.319        0.7250          0.000002     0.189   \n",
      "1         0.500   11    -7.996        0.0024          0.000000     0.133   \n",
      "2         0.422   10    -7.215        0.1090          0.000000     0.722   \n",
      "3         0.708    5    -5.426        0.0136          0.002210     0.118   \n",
      "4         0.657    9    -8.351        0.7050          0.000009     0.084   \n",
      "\n",
      "   valence    tempo  popular  \n",
      "0    0.354  131.955      1.0  \n",
      "1    0.515   77.383      0.0  \n",
      "2    0.331   74.980      1.0  \n",
      "3    0.734  122.006      1.0  \n",
      "4    0.381  141.735      1.0  \n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "train_data = pd.read_csv(\"train-songs.csv\")\n",
    "print(train_data.head())\n",
    "train_X = train_data[['danceability', 'key', 'loudness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo' ]].values\n",
    "train_y = train_data['popular'].values\n",
    "\n",
    "test_data = pd.read_csv(\"test-songs.csv\")\n",
    "print(test_data.head())\n",
    "test_X = test_data[['danceability', 'key', 'loudness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo' ]].values\n",
    "test_y = test_data['popular'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   i\\. Implement a function that draws a bootstrap sample of size N from the train dataset, where N can be specified by the user.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bootstrap(train_X,train_y,N):\n",
    "    n_rows, n_cols = train_X.shape\n",
    "    samples = np.random.choice(a=n_rows, size=N, replace=True)\n",
    "    return train_X[samples], train_y[samples]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ii\\. Complete the implementation of the random forest algorithm. For this task you may use the DecisionTreeClassifier from the scikit-learn library. The other parts of the random forest algorithm must be implemented using only Scipy/Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "   def __init__(self,n_trees,max_features,max_samples,min_node_size, max_depth):\n",
    "        #Initialize list containing weak classifiers. Also initialize any other parameter if required.\n",
    "        self.num_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.max_samples = max_samples\n",
    "        # To store individually trained decision trees\n",
    "        self.decision_trees = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   def train(self,train_X,train_y):\n",
    "    if len(self.decision_trees) > 0:\n",
    "        self.decision_trees = []\n",
    "\n",
    "    if isinstance(train_X, pd.core.frame.DataFrame):\n",
    "        train_X = train_X.values\n",
    "    if isinstance(train_y, pd.core.series.Series):\n",
    "        train_y = train_y.values\n",
    "        \n",
    "    # Training each weak classifier            \n",
    "    # Build each tree of the forest\n",
    "    tree_built = 0\n",
    "\n",
    "    while tree_built < self.num_trees:\n",
    "        clf = DecisionTreeClassifier(\n",
    "        max_depth=self.max_depth,\n",
    "        max_features=self.max_features,\n",
    "        )\n",
    "\n",
    "        # Obtain data sample\n",
    "        _X, _y = generate_bootstrap(train_X, train_y, self.max_samples)\n",
    "        # Train\n",
    "        clf.fit(_X, _y)\n",
    "        # Save the classifier\n",
    "        self.decision_trees.append(clf)\n",
    "        tree_built += 1\n",
    "\n",
    "\n",
    "   \n",
    "   def predict(self,test_X):\n",
    "    #Final predictions are obtained by taking majority-vote (most frequent class) from each weak classifier prediction\n",
    "    y = []\n",
    "    for tree in self.decision_trees:\n",
    "        y.append(tree.predict(test_X))\n",
    "        \n",
    "    y = np.swapaxes(y, axis1=0, axis2=1)\n",
    "        \n",
    "    # Use majority voting for the final prediction\n",
    "    predicted_classes = stats.mode(y,axis=1, keepdims=True)[0].reshape(-1)\n",
    "    \n",
    "    # return y_predictions\n",
    "    return predicted_classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii\\. Train the model for the dataset from train-songs.csv using the parameters given below.\n",
    "| Parameter| Value|\n",
    "|----------|------|\n",
    "Number of trees|100|\n",
    "Maximum features per tree|2|\n",
    "Bootstrap sample size|20000|\n",
    "Minimum node size|1|\n",
    "Maximum tree depth|10|\n",
    "\n",
    "\n",
    "Note: The bootstrap sample size is the same as train dataset size in this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Run this cell without any changes. The model will train if the implementation of subtask (ii) is correct.\n",
    "\n",
    "random_forest_model = RandomForest(n_trees=100, max_samples=20000,max_depth=10,min_node_size=1, max_features=2 )\n",
    "\n",
    "random_forest_model.train(train_X, train_y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   iv\\. Calculate the accuracy of the model using the test dataset and compare your results with the\n",
    "RandomForestClassifier from the scikit-learn library using the following parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of the Model: 80.65 %\n"
     ]
    }
   ],
   "source": [
    "# TODO Run predict for test data and calculate accuracy\n",
    "\n",
    "pred_class = random_forest_model.predict(test_X)\n",
    "\n",
    "rows = test_y.shape[0]\n",
    "\n",
    "print(\"Training Accuracy of the Model:\", (sum(pred_class==test_y)*100/rows),\"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using scikit-learn: 0.805\n",
      "Training Accuracy using scikit-learn: 80.5 %\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train and predict using scikit-learn library\n",
    "clf=RandomForestClassifier(n_estimators=100, max_samples=20000,max_depth=10, max_features=2)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(train_X,train_y)\n",
    "\n",
    "y_pred=clf.predict(test_X)\n",
    "from sklearn import metrics\n",
    "# Model Accuracy\n",
    "print(\"Accuracy using scikit-learn:\",metrics.accuracy_score(test_y, y_pred))\n",
    "print(\"Training Accuracy using scikit-learn:\", (sum(y_pred==test_y)*100/rows),\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c617624a7fd88b4018bd9e75be0d58c4afb6a334791d511af9b9a5162b5af2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
